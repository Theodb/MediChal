{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from nt_toolbox.graph import *\n",
    "from nt_toolbox.signal import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(image, alpha=0.5):\n",
    "    image_copy = np.zeros(image.shape)\n",
    "    image_copy[image > alpha] = 1\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_points_in_images(img):\n",
    "    '''\n",
    "    img : image \n",
    "    \n",
    "    return : True or False\n",
    "             True : there are points inside the cell \n",
    "             False : there aren't points inside the cell\n",
    "    '''\n",
    "    img = img*img\n",
    "    max_value = np.max(img)\n",
    "    min_value = np.min(img)\n",
    "    mean_value = np.mean(img)\n",
    "    b_img1 = binary(img, mean_value)\n",
    "    b_img2 = binary(img, (min_value + mean_value)/2)\n",
    "    return abs(np.sum(b_img1-b_img2)) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(images_paths, label):\n",
    "    p_detected = []\n",
    "    var_color = []\n",
    "    max_color = []\n",
    "    var_gray = []\n",
    "    max_gray = []\n",
    "    labels = []\n",
    "    \n",
    "    for ip in images_paths:\n",
    "        image = load_image(ip)\n",
    "        #print(image[15])\n",
    "        image_grey = np.asarray(Image.open(ip).convert('L'))\n",
    "        p_detected.append(1 if has_points_in_images(image) else 0)\n",
    "        var_color.append(np.array(image)[:,0].var())\n",
    "        max_color.append(np.array(image)[:,0].max())\n",
    "        var_gray.append(image_grey.var())\n",
    "        max_gray.append(image_grey.max())\n",
    "        labels.append(label)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    #df['image_path'] = images_paths\n",
    "    df['has_points'] = p_detected\n",
    "    df['var_color'] = var_color\n",
    "    df['max_color'] = max_color\n",
    "    df['var_gray'] = var_gray\n",
    "    df['max_gray'] = max_gray\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('../cell_images/Uninfected'):\n",
    "    paths = []\n",
    "    for filename in filenames[:500]:\n",
    "        image_path = os.path.join(dirname, filename)\n",
    "        paths.append(image_path)\n",
    "    df1 = extract(paths, 0)\n",
    "    '''\n",
    "    for filename in filenames[:100]:\n",
    "        image_path = os.path.join(dirname, filename)\n",
    "        if image_path.endswith('.db'):\n",
    "            continue\n",
    "        image = load_image(image_path)\n",
    "        p_labels.append(True)\n",
    "        if not has_points_in_images():\n",
    "            p_detected.append(True)\n",
    "        else:\n",
    "            imageplot(image)\n",
    "            p_detected.append(False)\n",
    "            print(image_path)    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "for dirname, _, filenames in os.walk('../cell_images/Parasitized'):\n",
    "    paths = []\n",
    "    for filename in filenames[:500]:\n",
    "        image_path = os.path.join(dirname, filename)\n",
    "        paths.append(image_path)\n",
    "    df2 = extract(paths, 1)\n",
    "\n",
    "df = df1.append(df2)\n",
    "\n",
    "# shuffle data\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# train = 60% / test = 20% / validation = 20%\n",
    "train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "features = [\"has_points\", \"var_color\", \"max_color\", \"var_gray\", \"max_gray\"]\n",
    "\n",
    "train.to_csv(\"malaria_train.data\", sep=' ', columns = features, index=False)\n",
    "train.to_csv(\"malaria_train.solution\", sep=' ', columns = [\"label\"], index=False)\n",
    "\n",
    "test.to_csv(\"malaria_test.data\", sep=' ', columns = features, index=False)\n",
    "test.to_csv(\"malaria_test.solution\", sep=' ', columns = [\"label\"], index=False)\n",
    "\n",
    "validate.to_csv(\"malaria_valid.data\", sep=' ', columns = features, index=False)\n",
    "validate.to_csv(\"malaria_valid.solution\", sep=' ', columns = [\"label\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['has_points'] ==[0 for i in range(len(df['has_points']))] ) / len(df['has_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/nicolas/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lin_clf = svm.SVC()\n",
    "\n",
    "train_x = train.drop(columns=[\"label\", \"has_points\", \"var_gray\", \"max_gray\"])\n",
    "train_y = train.drop(columns=[\"has_points\", \"var_color\", \"max_color\", \"var_gray\", \"max_gray\"])\n",
    "\n",
    "test_x = test.drop(columns=[\"label\", \"has_points\", \"var_gray\", \"max_gray\"])\n",
    "test_y = test.drop(columns=[\"has_points\", \"var_color\", \"max_color\", \"var_gray\", \"max_gray\"])\n",
    "\n",
    "lin_clf.fit(train_x, train_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1\n",
      " 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1]\n",
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "Score : 0.52\n"
     ]
    }
   ],
   "source": [
    "# predictions = lin_clf.predict(test_x)\n",
    "# score = 0\n",
    "\n",
    "# test_y = [ x[0] for x in test_y.values.tolist()]\n",
    "\n",
    "# for i in range(len(predictions)):\n",
    "#     if predictions[i] == test_y[i]:\n",
    "#         score += 1\n",
    "        \n",
    "# print(\"Score : \" + str(score/len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
